{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Line Extending Game 0\n",
    "Here, we:\n",
    "1. Introduce the \"two-pixel line extending game\"\n",
    "2. Use reinforcement learning to learn to play the game\n",
    "3. Use reinforcement learning to learn *rules* to play the game\n",
    "\n",
    "Throughout the notebook, helper functions whose implementations are not important are factored out into a library file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import warnings\n",
    "from collections import Counter\n",
    "from abc import ABC, abstractmethod\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from nltk import CFG, PCFG, Nonterminal\n",
    "from nltk.parse.generate import generate\n",
    "from nltk.tokenize import wordpunct_tokenize\n",
    "from nltk.parse.recursivedescent import RecursiveDescentParser\n",
    "from nltk.tree.tree import Tree\n",
    "\n",
    "from nsai_experiments import line_extending_game_tools as lgt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1: The two-pixel line extending game"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction to the game"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imagine a NxN grid of pixels that can either be on (`x`) or off (`-`), represented by a NumPy Boolean array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[False False False False False]\n",
      " [ True False False False False]\n",
      " [ True False False  True False]\n",
      " [False False  True False False]\n",
      " [False False False False False]]\n",
      "- - - - -\n",
      "x - - - -\n",
      "x - - x -\n",
      "- - x - -\n",
      "- - - - -\n"
     ]
    }
   ],
   "source": [
    "sample_grid = lgt.create_grid(\"\"\"\n",
    "    - - - - -\n",
    "    x - - - -\n",
    "    x - - x -\n",
    "    - - x - -\n",
    "    - - - - -\n",
    "    \"\"\")\n",
    "print(sample_grid)\n",
    "lgt.display_grid(sample_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The game is: for every \"line segment\" consisting of at least two contiguous `x`s, extend the segment all the way across the grid. For instance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- - - - - - - - - -\n",
      "- - x - - x - - - -\n",
      "- x - - x - - - - -\n",
      "- - - - - - - - - -\n",
      "- - - - - - - - - -\n",
      "- - - - - - - - - -\n",
      "- - - - - - - - - -\n",
      "- - - - - - - - - -\n",
      "- - - - - - - x x -\n",
      "- - - - - - - - - -\n",
      "\n",
      "- - - x - - x - - -\n",
      "- - x - - x - - - -\n",
      "- x - - x - - - - -\n",
      "x - - x - - - - - -\n",
      "- - x - - - - - - -\n",
      "- x - - - - - - - -\n",
      "x - - - - - - - - -\n",
      "- - - - - - - - - -\n",
      "x x x x x x x x x x\n",
      "- - - - - - - - - -\n"
     ]
    }
   ],
   "source": [
    "sample_start1 = lgt.create_grid(\"\"\"\n",
    "    - - - - - - - - - - \n",
    "    - - x - - x - - - - \n",
    "    - x - - x - - - - - \n",
    "    - - - - - - - - - - \n",
    "    - - - - - - - - - - \n",
    "    - - - - - - - - - - \n",
    "    - - - - - - - - - - \n",
    "    - - - - - - - - - - \n",
    "    - - - - - - - x x - \n",
    "    - - - - - - - - - - \n",
    "    \"\"\")\n",
    "\n",
    "sample_final1 = lgt.create_grid(\"\"\"\n",
    "    - - - x - - x - - - \n",
    "    - - x - - x - - - - \n",
    "    - x - - x - - - - - \n",
    "    x - - x - - - - - - \n",
    "    - - x - - - - - - - \n",
    "    - x - - - - - - - - \n",
    "    x - - - - - - - - - \n",
    "    - - - - - - - - - - \n",
    "    x x x x x x x x x x \n",
    "    - - - - - - - - - -  \n",
    "    \"\"\")\n",
    "\n",
    "lgt.display_grid(sample_start1)\n",
    "print()\n",
    "lgt.display_grid(sample_final1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The game is played in moves, where each move consists of changing one `-` to an `x`. For simplicity in this very basic version of the game, we disallow starting states that correspond to final states containing line segments not part of a line. For instance, this is disallowed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- - - - - - - - - -\n",
      "- - x - - - - - - -\n",
      "- - x - - - - - - -\n",
      "- - - - - - - - - -\n",
      "- - - - - - - - - -\n",
      "- - - - - - - - - -\n",
      "- - - - - - - - - -\n",
      "- - - - - - - - - -\n",
      "- - - - - - x x - -\n",
      "- - - - - - - - - -\n",
      "\n",
      "- - x - - - - - - -\n",
      "- - x - - - - - - -\n",
      "- - x - - - - - - -\n",
      "- - x - - - - - - -\n",
      "- - x - - - - - - -\n",
      "- - x - - - - - - -\n",
      "- - x - - - - - - -\n",
      "- - x - - - - - - -\n",
      "x x x x x x x x x x\n",
      "- - x - - - - - - -\n"
     ]
    }
   ],
   "source": [
    "bad_start = lgt.create_grid(\"\"\"\n",
    "    - - - - - - - - - -\n",
    "    - - x - - - - - - -\n",
    "    - - x - - - - - - -\n",
    "    - - - - - - - - - -\n",
    "    - - - - - - - - - -\n",
    "    - - - - - - - - - -\n",
    "    - - - - - - - - - -\n",
    "    - - - - - - - - - -\n",
    "    - - - - - - x x - -\n",
    "    - - - - - - - - - -\n",
    "    \"\"\")\n",
    "\n",
    "bad_final = lgt.create_grid(\"\"\"\n",
    "    - - x - - - - - - -\n",
    "    - - x - - - - - - -\n",
    "    - - x - - - - - - -\n",
    "    - - x - - - - - - -\n",
    "    - - x - - - - - - -\n",
    "    - - x - - - - - - -\n",
    "    - - x - - - - - - -\n",
    "    - - x - - - - - - -\n",
    "    x x x x x x x x x x\n",
    "    - - x - - - - - - -\n",
    "    \"\"\")\n",
    "\n",
    "lgt.display_grid(bad_start)\n",
    "print()\n",
    "lgt.display_grid(bad_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "because its final state contains several diagonal line segments not part of lines. For the two-pixel version, this means that, with a few exceptions, lines cannot touch each other. This rule gives our game the useful property that if grid A can be transformed into grid B with one move, a solution for grid B plus that one move is a solution for grid A."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A First Human Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this convenient modification, an intuitive solution to the game is: whenever you see a line segment, extend it on one of the ends if possible; repeat until no more moves are possible; then the game is solved. Here's an implementation of that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- - - - - - - - - -\n",
      "- - x - - x - - - -\n",
      "- x - - x - - - - -\n",
      "- - - - - - - - - -\n",
      "- - - - - - - - - -\n",
      "- - - - - - - - - -\n",
      "- - - - - - - - - -\n",
      "- - - - - - - - - -\n",
      "- - - - - - - x x -\n",
      "- - - - - - - - - -\n",
      "6 initial possible moves... down to 6 due to out of bounds... down to 6 due to already filled in\n",
      "8 initial possible moves... down to 7 due to out of bounds... down to 5 due to already filled in\n",
      "10 initial possible moves... down to 9 due to out of bounds... down to 5 due to already filled in\n",
      "12 initial possible moves... down to 11 due to out of bounds... down to 5 due to already filled in\n",
      "14 initial possible moves... down to 12 due to out of bounds... down to 4 due to already filled in\n",
      "16 initial possible moves... down to 14 due to out of bounds... down to 4 due to already filled in\n",
      "18 initial possible moves... down to 15 due to out of bounds... down to 3 due to already filled in\n",
      "20 initial possible moves... down to 16 due to out of bounds... down to 2 due to already filled in\n",
      "22 initial possible moves... down to 18 due to out of bounds... down to 2 due to already filled in\n",
      "24 initial possible moves... down to 19 due to out of bounds... down to 1 due to already filled in\n",
      "26 initial possible moves... down to 21 due to out of bounds... down to 1 due to already filled in\n",
      "28 initial possible moves... down to 23 due to out of bounds... down to 1 due to already filled in\n",
      "30 initial possible moves... down to 25 due to out of bounds... down to 1 due to already filled in\n",
      "32 initial possible moves... down to 27 due to out of bounds... down to 1 due to already filled in\n",
      "34 initial possible moves... down to 29 due to out of bounds... down to 1 due to already filled in\n",
      "36 initial possible moves... down to 30 due to out of bounds... down to 0 due to already filled in\n",
      "Success after 16 iterations!\n",
      "- - - x - - x - - -\n",
      "- - x - - x - - - -\n",
      "- x - - x - - - - -\n",
      "x - - x - - - - - -\n",
      "- - x - - - - - - -\n",
      "- x - - - - - - - -\n",
      "x - - - - - - - - -\n",
      "- - - - - - - - - -\n",
      "x x x x x x x x x x\n",
      "- - - - - - - - - -\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Takes a segment and direction and outputs the coordinates of the points on each end of the\n",
    "segment that we'd want to extend\n",
    "\"\"\"\n",
    "def where_to_extend(segment, direction):\n",
    "    (a, b), (c, d) = segment\n",
    "    match direction:\n",
    "        case \"HORIZONTAL\": return (a, b-1), (c, d+1)\n",
    "        case \"VERTICAL\":   return (a-1, b), (c+1, d)\n",
    "        case \"SLOPE_DOWN\": return (a-1, b-1), (c+1, d+1)\n",
    "        case \"SLOPE_UP\":   return (a+1, b-1), (c-1, d+1)\n",
    "\n",
    "def solve_human(unsolved_problem, timeout = 100, random_seed = 47, print_status = False):\n",
    "    random.seed(random_seed)\n",
    "    rows, cols = np.shape(unsolved_problem)\n",
    "    answer = np.copy(unsolved_problem)\n",
    "    # Each iteration is a move in the game; note that we only need to refer to the current state (not the starting state) to find the next move\n",
    "    for i in range(timeout):\n",
    "        # Find all possible line segments and the points we'd want to fill in to extend those segments\n",
    "        segments, directions = lgt.find_all_segments(answer)\n",
    "        possible_moves = [point\n",
    "                              for (segment, direction) in zip(segments, directions)\n",
    "                                  for point in where_to_extend(segment, direction)]\n",
    "        \n",
    "        # Exclude points that are off the board and points that have already been filled in\n",
    "        if print_status: print(f\"{len(possible_moves)} initial possible moves... \", end = \"\")\n",
    "        possible_moves = list(filter(lambda point: 0 <= point[0] < rows and 0 <= point[1] < cols, possible_moves))\n",
    "        if print_status: print(f\"down to {len(possible_moves)} due to out of bounds... \", end = \"\")\n",
    "        possible_moves = list(filter(lambda point: not answer[point[0], point[1]], possible_moves))\n",
    "        if print_status: print(f\"down to {len(possible_moves)} due to already filled in\")\n",
    "        \n",
    "        # End or choose a random move from the possible points\n",
    "        if len(possible_moves) == 0:\n",
    "            if print_status: print(f\"Success after {i+1} iterations!\")\n",
    "            return answer\n",
    "        my_move = random.choice(possible_moves)\n",
    "        answer[my_move] = True\n",
    "    if print_status: print(f\"Timed out after {timeout} iterations\")\n",
    "    return answer\n",
    "\n",
    "lgt.display_grid(sample_start1)\n",
    "human_answer = solve_human(sample_start1, print_status = True)\n",
    "lgt.display_grid(human_answer)\n",
    "\n",
    "assert np.array_equal(human_answer, sample_final1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obviously this is not the most efficient solution — we are starting completely from scratch every iteration and, for most of the game, most of the candidate moves are already filled in — but it is easy to understand. Let's generate some (problem, solution) pairs and test that the algorithm works:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- - - - - - - - - -\n",
      "- - x - - - - x - -\n",
      "- x - x - - - - - x\n",
      "x - - - - - - - x -\n",
      "- - - - - - - x - -\n",
      "- - - - - - x - - -\n",
      "- x - - - - - x - -\n",
      "- - - - - - - - - -\n",
      "- - - - - - - - - -\n",
      "- - - - - - - - - -\n"
     ]
    }
   ],
   "source": [
    "lgt.display_grid(lgt.generate_problem(10, 10, 2, 2, 2)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(47)\n",
    "for i in range(100):\n",
    "    # Generate a problem with the given dimensions and number of three-length segments,\n",
    "    # two-length features, and one-length features; and the corresponding solution\n",
    "    problem, solution = lgt.generate_problem(10, 10, random.randrange(2), random.randrange(3), random.randrange(4))\n",
    "    assert np.array_equal(solve_human(problem), solution)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Another Human Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The approach above seems simple, but it's actually built upon some facts we already knew — most notablly, how to find segments (the `lgt.find_all_segments` helper function). Let's implement an even simpler solution. We imagine an agent moving around the board, turning on all the pixels it deems necessary in a certain area before moving on. We'll give the agent a \"view\" of a 5x5 square centered on the active pixel (thereby encoding \"for free\" the knowledge that what to do for each pixel depends only on the values of pixels a maximum of 2 pixels away) and let it make two actions: turn on the pixel or move to the next cell. We'll also give the agent for free that it is not possible to activate a pixel that is already activated. We will drag this agent across the entire board until it makes a full pass without activating any pixels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RunnableGridAgent(ABC):\n",
    "    \"\"\"\n",
    "    Initialize the agent for a grid with `n_rows` rows and `n_cols` cols; give it a state\n",
    "    window of height `window_rows*2+1` and width `window_cols*2+1`.\n",
    "    \"\"\"\n",
    "    def __init__(self, *, window_rows = 2, window_cols = 2):\n",
    "        self._window_rows = window_rows\n",
    "        self._window_cols = window_cols\n",
    "        self._cells_traversed = 0\n",
    "    \n",
    "    \"\"\"\n",
    "    Set the grid that the agent operates on; place the agent at the top left corner. Creates\n",
    "    a copy of the grid; subsequent operations will not mutate the original.\n",
    "    \"\"\"\n",
    "    def set_grid(self, grid):\n",
    "        self._n_rows, self._n_cols = grid.shape\n",
    "        # Probability of moving on during exploration. Chosen so that 10% of cells\n",
    "        # are filled in after max(n_rows, n_cols) full passes over the grid\n",
    "        self._padded_grid = np.pad(grid, ((self._window_rows, self._window_rows), (self._window_cols, self._window_cols)))\n",
    "        self._my_row = 0\n",
    "        self._my_col = 0\n",
    "        self._actions_taken = []\n",
    "        self._action_locations = []\n",
    "\n",
    "    \"Mark the current cell as on\"\n",
    "    def activate_current_cell(self):\n",
    "        self._padded_grid[self._window_rows+self._my_row, self._window_cols+self._my_col] = True\n",
    "\n",
    "    \"Read the current cell\"\n",
    "    def read_current_cell(self):\n",
    "        return self._padded_grid[self._window_rows+self._my_row, self._window_cols+self._my_col]\n",
    "    \n",
    "    \"Get the grid with whatever modifications the agent has made to it so far\"\n",
    "    def get_grid(self):\n",
    "        return self._padded_grid[self._window_rows:-self._window_rows, self._window_cols:-self._window_cols]\n",
    "    \n",
    "    \"Count the total number of filled cells in the current grid\"\n",
    "    def count_filled_cells(self):\n",
    "        return np.sum(self.get_grid())\n",
    "    \n",
    "    \"Get the current agent state as a grid centered on the active cell (which is technically not part of the state)\"\n",
    "    def current_state_grid(self):\n",
    "        return self._padded_grid[\n",
    "            self._my_row:self._my_row+self._window_rows*2+1,\n",
    "            self._my_col:self._my_col+self._window_cols*2+1]\n",
    "    \n",
    "    \"Flatten a state grid and remove the center cell\"\n",
    "    def flatten_subgrid(self, subgrid):\n",
    "        rows, cols = subgrid.shape\n",
    "        assert rows % 2 == cols % 2 == 1\n",
    "        return np.delete(subgrid.flatten(), cols*(rows//2)+cols//2)\n",
    "\n",
    "    \"Use binary to encode the current agent state as an integer for `q_table` indexing\"\n",
    "    def _state_grid_to_n(self, state_grid):\n",
    "        tr, tc = self._window_rows*2+1, self._window_cols*2+1\n",
    "        assert np.shape(state_grid) == (tr, tc)\n",
    "        without_center_cell = self.flatten_subgrid(state_grid)\n",
    "        return without_center_cell.dot(2**np.arange(tr*tc-1)[::-1])\n",
    "    \n",
    "    \"Apply the real policy to the state grid `s` to produce an action\"\n",
    "    @abstractmethod\n",
    "    def real_policy(self, s):\n",
    "        raise NotImplementedError()\n",
    "    \n",
    "    \"Move the agent to its next position on the board; wrap around at the end\"\n",
    "    def increment_position(self):\n",
    "        self._my_col += 1\n",
    "        if self._my_col >= self._n_cols:\n",
    "            self._my_row += 1\n",
    "            self._my_col = 0\n",
    "        if self._my_row >= self._n_rows:\n",
    "            self._my_row = 0\n",
    "        self._cells_traversed += 1\n",
    "    \n",
    "    \"Perform a step with the given policy (defaults to real)\"\n",
    "    def step(self, policy = None, verbose = False):\n",
    "        if policy is None: policy = self.real_policy\n",
    "        state = self.current_state_grid()\n",
    "        \n",
    "        # If the current cell is already filled in, move on without consulting the policy\n",
    "        if self.read_current_cell():\n",
    "            action = 0\n",
    "            if verbose: print(\"Moving on as active cell is already filled in\")\n",
    "        else:\n",
    "            action = policy(state)\n",
    "            self._actions_taken.append((self._state_grid_to_n(state), action))\n",
    "            self._action_locations.append((self._my_row, self._my_col))  # surprise tool that will help us later\n",
    "            if verbose: print(f\"Policy evaluates to action {action}\")\n",
    "        \n",
    "        if action:\n",
    "            self.activate_current_cell()\n",
    "        else:\n",
    "            self.increment_position()\n",
    "        if verbose: print(f\"Position is now {(self._my_row, self._my_col)}\")\n",
    "        return action\n",
    "    \n",
    "    \"Get the number of cells traversed so far\"\n",
    "    def get_cells_traversed(self):\n",
    "        return self._cells_traversed\n",
    "    \n",
    "    \"Provide a single number that captures how well we did against a true answer grid\"\n",
    "    def evaluate_goodness(self, answer_grid):\n",
    "        # A cell counts against us if its true value differs from the predicted value -- that's xor\n",
    "        return -np.sum(np.abs(answer_grid ^ self.get_grid()))\n",
    "    \n",
    "    \"\"\"\n",
    "    Run the agent on the grid `problem` using the real policy; stop when the agent has made\n",
    "    a full pass over the grid without filling any cells or when `timeout` steps have been\n",
    "    made\n",
    "    \"\"\"\n",
    "    def run(self, problem, timeout = 100_000):\n",
    "        self.set_grid(problem)\n",
    "        n_cells = self._n_rows*self._n_cols\n",
    "        i_last_updated = -1\n",
    "        filled_cells = self.count_filled_cells()\n",
    "        for i in range(timeout):\n",
    "            self.step(self.real_policy)\n",
    "            new_filled_cells = self.count_filled_cells()\n",
    "            if new_filled_cells > filled_cells:\n",
    "                i_last_updated = i\n",
    "            if i-i_last_updated >= n_cells:\n",
    "                return self.get_grid()\n",
    "            filled_cells = new_filled_cells\n",
    "        warnings.warn(\"Run timed out without finishing\")\n",
    "        return self.get_grid()\n",
    "    \n",
    "    \"`run` the agent and return its performance\"\n",
    "    def test(self, problem, solution, timeout = 100_000):\n",
    "        self.run(problem, timeout = timeout)\n",
    "        return self.evaluate_goodness(solution)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the human solution, we implement the following `real_policy`, which encodes all the pairs of cells that imply a segment that should be extended at the active cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HumanAgent(RunnableGridAgent):\n",
    "    def real_policy(self, s):\n",
    "        return (s[0, 2] and s[1, 2]) \\\n",
    "            or (s[0, 4] and s[1, 3]) \\\n",
    "            or (s[2, 4] and s[2, 3]) \\\n",
    "            or (s[4, 4] and s[3, 3]) \\\n",
    "            or (s[4, 2] and s[3, 2]) \\\n",
    "            or (s[4, 0] and s[3, 1]) \\\n",
    "            or (s[2, 0] and s[2, 1]) \\\n",
    "            or (s[0, 0] and s[1, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "human_agent = HumanAgent()\n",
    "\n",
    "random.seed(47)\n",
    "for i in range(100):\n",
    "    problem, solution = lgt.generate_problem(10, 10, random.randrange(2), random.randrange(3), random.randrange(4))\n",
    "    assert np.array_equal(human_agent.run(problem), solution)\n",
    "    assert human_agent.test(problem, solution) == 0  # equivalently"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2: A Reinforcement Learning Player"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Traditional RL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's use traditional reinforcement learning to teach an agent how to play the game. The development of this RL agent, inspired by Q-learning, turned out to require some iteration, so I factored that process out into `line_extending_trad_rl.ipynb`. Here, I'll describe the more or less successful design I ended up with."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We keep the formulation of an agent moving around the board, making decisions about an active pixel based on the 5x5 grid around it. The agent's policy is represented by a table where the rows are each possible state — all $2^{5*5-1} = 16,777,216$ of them — the columns are each possible action — either fill in the active pixel or move on — and the values are the quality of taking that action given that state. (In practice, we'll use two tables so that we can normalize values by the number of times they were trained.) For training, we'll use an exploration policy that initially makes random decisions biased towards the \"move on\" action and starts to follow the real policy closer and closer as training proceeds. We'll consider the training agent done with a given grid when it has activated the same number of pixels as are activated in the answer and then made a full pass over the grid after that. We will then compare the agent-generated grid to the solution grid and use the value of each pixel to update the weights that influenced that pixel (an earlier approach that reduced the difference between the agent-generated grid and the solution grid to a single number was not successful, or trained too slowly to demonstrate its success).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainableGridAgent(RunnableGridAgent):\n",
    "    \"\"\"\n",
    "    Initialize the agent for a grid with `n_rows` rows and `n_cols` cols; give it a state\n",
    "    window of height `window_rows*2+1` and width `window_cols*2+1`; call `random_source` for\n",
    "    a source of randomness.\n",
    "    \"\"\"\n",
    "    def __init__(self, *, window_rows = 2, window_cols = 2, random_source = random.random):\n",
    "        super().__init__(window_rows = window_rows, window_cols = window_cols)\n",
    "        self._random_source = random_source\n",
    "    \n",
    "    def set_grid(self, grid):\n",
    "        super().set_grid(grid)\n",
    "        self._exploration_bias = 1 - 0.1/max(self._n_rows, self._n_cols)\n",
    "\n",
    "    \"Apply the exploration policy to the state grid `s` to produce an action\"\n",
    "    def exploration_policy(self, s):\n",
    "        if self._random_source() < self._exploration_rate:\n",
    "            return int(self._random_source() >= self._exploration_bias)\n",
    "        return self.real_policy(s)\n",
    "\n",
    "    \"Gets called at the end of a call to `train` to update the model\"\n",
    "    @abstractmethod\n",
    "    def update_model(self, solution):\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    \"\"\"\n",
    "    Set the agent loose on the grid `problem` using the exploration policy with the given\n",
    "    `exploration_rate`; use the grid `solution` to update the weights\n",
    "    \"\"\"\n",
    "    def train(self, problem, solution, exploration_rate = 1.0, verbose = False):\n",
    "        self.set_grid(problem)\n",
    "        self._exploration_rate = exploration_rate\n",
    "        while self.count_filled_cells() < np.sum(solution):\n",
    "            self.step(self.exploration_policy)\n",
    "        for i in range(self._n_rows*self._n_cols):\n",
    "            self.step(self.exploration_policy)\n",
    "        if verbose:\n",
    "            print(f\"Completed in {self._cells_traversed} steps with {len(self._actions_taken)} exploratory actions taken\")\n",
    "            print(f\"{np.count_nonzero(self.get_grid() == solution)} matches out of {self._n_rows*self._n_cols}\")\n",
    "        self.update_model(solution)\n",
    "        return self.get_grid()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Created from the successful agent we ended up with in `line_extending_trad_rl.ipynb`\n",
    "class WorkingTraditionalAgent(TrainableGridAgent):\n",
    "    def __init__(self, *, window_rows = 2, window_cols = 2, random_source = random.random):\n",
    "        super().__init__(window_rows = window_rows, window_cols = window_cols, random_source = random_source)\n",
    "        # PERF might be better to store these together for better caching performance\n",
    "        # Rows are state, cols are action (0 = move on, 1 = fill in), vals are q-value numerator\n",
    "        self._q_table = np.zeros((2**((window_rows*2+1)*(window_cols*2+1)-1), 2), dtype=np.int64)\n",
    "        # Rows are state, cols are action, vals are # of times encountered in training data\n",
    "        self._times_encountered = np.zeros_like(self._q_table)\n",
    "    \n",
    "    \"Apply the real policy to the state grid `s` to produce an action\"\n",
    "    def real_policy(self, s):\n",
    "        idx = self._state_grid_to_n(s)\n",
    "        q_row = self._q_table[idx]\n",
    "        te_row = self._times_encountered[idx]\n",
    "        with np.errstate(invalid = \"ignore\"): q_quotient = q_row/te_row\n",
    "        if len(q_quotient[np.isnan(q_quotient)]) == len(q_quotient):\n",
    "            warnings.warn(\"Encountered situation where all options lack training data, defaulting to 0\")\n",
    "            return 0\n",
    "        elif len(q_quotient[np.isnan(q_quotient)]) > 0:\n",
    "            warnings.warn(\"Encountered situation where some option lacks training data\")\n",
    "            q_quotient[np.isnan(q_quotient)] = -np.inf  # Never choose the option that hasn't been trained\n",
    "        return np.argmax(q_quotient)\n",
    "    \n",
    "    \"Update weights based on how our solution differs from the true solution\"\n",
    "    def update_model(self, solution, *, pass_reward = 10, pass_penalty = -1, fill_reward = 100, fill_penalty = -100):\n",
    "        self._normalized_q = None\n",
    "        actions_taken = np.array(self._actions_taken)  # Two columns: _state_grid_to_n, action (0 or 1)\n",
    "        action_locations = np.array(self._action_locations)  # Two columns: row, col\n",
    "        for irow in range(self._n_rows):\n",
    "            for icol in range(self._n_cols):\n",
    "                # All the decisions that happened at this cell (two columns: state n, action)\n",
    "                relevant_actions = actions_taken[(action_locations[:, 0] == irow) & (action_locations[:, 1] == icol)]\n",
    "                yes_indices = relevant_actions[:, 0][relevant_actions[:, 1] == 1]  # state ns where action is 0\n",
    "                no_indices = relevant_actions[:, 0][relevant_actions[:, 1] == 0]  # state ns where action is 1\n",
    "                predicted = self.get_grid()[irow, icol]\n",
    "                actual = solution[irow, icol]\n",
    "                match (predicted, actual):\n",
    "                    case (np.True_, np.False_):  # false positive\n",
    "                        # If we said yes and real was no, reward all nos, penalize the yes\n",
    "                        self._q_table[no_indices, 0] += pass_reward\n",
    "                        self._q_table[yes_indices, 1] += fill_penalty\n",
    "                        self._times_encountered[no_indices, 0] += 1\n",
    "                        self._times_encountered[yes_indices, 1] += 1\n",
    "                    case (np.True_, np.True_):  # true positive\n",
    "                        # If we said yes and real was yes, nothing for nos, reward the yes\n",
    "                        self._q_table[yes_indices, 1] += fill_reward\n",
    "                        self._times_encountered[yes_indices, 1] += 1\n",
    "                    case (np.False_, np.False_):  # true negative\n",
    "                        # If we said no and real was no, reward all nos, there is no yes\n",
    "                        self._q_table[no_indices, 0] += pass_reward\n",
    "                        self._times_encountered[no_indices, 0] += 1\n",
    "                    case (np.False_, np.True_):  # false negative\n",
    "                        # If we said no and real was yes, penalize all nos, there is no yes\n",
    "                        self._q_table[no_indices, 0] += pass_penalty\n",
    "                        self._times_encountered[no_indices, 0] += 1\n",
    "                    case _:\n",
    "                        assert False, \"Failed to match any case\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To see how this works, we'll feed the agent a fake source of randomness to control its behavior:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "def fake_random_source(l):\n",
    "    it = iter(l)\n",
    "    return lambda: next(it)\n",
    "\n",
    "r = fake_random_source([0.0, 1.0])\n",
    "print(r())\n",
    "print(r())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So if we train it like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed in 75 steps with 68 exploratory actions taken\n",
      "30 matches out of 36\n",
      "x x x x - -\n",
      "- x - - - -\n",
      "- - x - - -\n",
      "- - - - - -\n",
      "- - - - - -\n",
      "- - - - - -\n"
     ]
    }
   ],
   "source": [
    "test_grid = lgt.create_grid(\"\"\"\n",
    "    - - - - - -\n",
    "    - x - - - -\n",
    "    - - x - - -\n",
    "    - - - - - -\n",
    "    - - - - - -\n",
    "    - - - - - -\n",
    "    \"\"\")\n",
    "test_answer = lgt.create_grid(\"\"\"\n",
    "    x - - - - -\n",
    "    - x - - - -\n",
    "    - - x - - -\n",
    "    - - - x - -\n",
    "    - - - - x -\n",
    "    - - - - - x\n",
    "    \"\"\")\n",
    "\n",
    "# Each time the exploration policy is called, randomness is used (a) to determine whether to\n",
    "# act randomly or follow the real policy and (b) if acting randomly, how to act. Here we\n",
    "# tell it to always act randomly, to make a full pass without activating any cells, to\n",
    "# activate four cells, and to make another full pass without activating any cells.\n",
    "test_agent = WorkingTraditionalAgent(random_source = fake_random_source([0.0, 0.0]*34 + [0.0, 1.0]*4 + [0.0, 0.0]*30))\n",
    "test_agent.train(test_grid, test_answer, verbose = True)\n",
    "lgt.display_grid(test_agent.get_grid())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we would expect moving on without activating to be encouraged at (1, 0) and discouraged at (3, 3), then activating the cell to be encouraged at (0, 0) and (once (0, 0) is activated) discouraged at (0, 1):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10  0]\n",
      "[-1  0]\n",
      "[  0 100]\n",
      "[   0 -100]\n"
     ]
    }
   ],
   "source": [
    "test_agent.set_grid(test_grid)\n",
    "\n",
    "for coords in [(1, 0), (3, 3), (0, 0), (0, 1)]:\n",
    "    test_agent._my_row, test_agent._my_col = coords\n",
    "    print(test_agent._q_table[test_agent._state_grid_to_n(test_agent.current_state_grid())])\n",
    "    if coords == (0, 0): test_agent.activate_current_cell()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great. Here's training the agent on a few thousand grids (takes about 12m on my machine):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training step 0 with an exploration rate of 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7_/d7tqnwgs3pb_q_t94nmtckdcx9mz_y/T/ipykernel_49124/2331923233.py:18: UserWarning: Encountered situation where all options lack training data, defaulting to 0\n",
      "  warnings.warn(\"Encountered situation where all options lack training data, defaulting to 0\")\n",
      "/var/folders/7_/d7tqnwgs3pb_q_t94nmtckdcx9mz_y/T/ipykernel_49124/2331923233.py:21: UserWarning: Encountered situation where some option lacks training data\n",
      "  warnings.warn(\"Encountered situation where some option lacks training data\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training step 1 with an exploration rate of 0.98\n",
      "Starting training step 2 with an exploration rate of 0.96\n",
      "Starting training step 3 with an exploration rate of 0.94\n",
      "Starting training step 4 with an exploration rate of 0.92\n",
      "Starting training step 5 with an exploration rate of 0.9\n",
      "Starting training step 6 with an exploration rate of 0.88\n",
      "Starting training step 7 with an exploration rate of 0.86\n",
      "Starting training step 8 with an exploration rate of 0.84\n",
      "Starting training step 9 with an exploration rate of 0.8200000000000001\n",
      "Starting training step 10 with an exploration rate of 0.8\n",
      "Starting training step 11 with an exploration rate of 0.78\n",
      "Starting training step 12 with an exploration rate of 0.76\n",
      "Starting training step 13 with an exploration rate of 0.74\n",
      "Starting training step 14 with an exploration rate of 0.72\n",
      "Starting training step 15 with an exploration rate of 0.7\n",
      "Starting training step 16 with an exploration rate of 0.6799999999999999\n",
      "Starting training step 17 with an exploration rate of 0.6599999999999999\n",
      "Starting training step 18 with an exploration rate of 0.64\n",
      "Starting training step 19 with an exploration rate of 0.62\n",
      "Starting training step 20 with an exploration rate of 0.6\n",
      "Starting training step 21 with an exploration rate of 0.5800000000000001\n",
      "Starting training step 22 with an exploration rate of 0.56\n",
      "Starting training step 23 with an exploration rate of 0.54\n",
      "Starting training step 24 with an exploration rate of 0.52\n",
      "Starting training step 25 with an exploration rate of 0.5\n",
      "Starting training step 26 with an exploration rate of 0.48\n",
      "Starting training step 27 with an exploration rate of 0.45999999999999996\n",
      "Starting training step 28 with an exploration rate of 0.43999999999999995\n",
      "Starting training step 29 with an exploration rate of 0.42000000000000004\n",
      "Starting training step 30 with an exploration rate of 0.4\n",
      "Starting training step 31 with an exploration rate of 0.38\n",
      "Starting training step 32 with an exploration rate of 0.36\n",
      "Starting training step 33 with an exploration rate of 0.33999999999999997\n",
      "Starting training step 34 with an exploration rate of 0.31999999999999995\n",
      "Starting training step 35 with an exploration rate of 0.30000000000000004\n",
      "Starting training step 36 with an exploration rate of 0.28\n",
      "Starting training step 37 with an exploration rate of 0.26\n",
      "Starting training step 38 with an exploration rate of 0.24\n",
      "Starting training step 39 with an exploration rate of 0.21999999999999997\n",
      "Starting training step 40 with an exploration rate of 0.19999999999999996\n",
      "Starting training step 41 with an exploration rate of 0.18000000000000005\n",
      "Starting training step 42 with an exploration rate of 0.16000000000000003\n",
      "Starting training step 43 with an exploration rate of 0.14\n",
      "Starting training step 44 with an exploration rate of 0.12\n",
      "Starting training step 45 with an exploration rate of 0.09999999999999998\n",
      "Starting training step 46 with an exploration rate of 0.07999999999999996\n",
      "Starting training step 47 with an exploration rate of 0.06000000000000005\n",
      "Starting training step 48 with an exploration rate of 0.040000000000000036\n",
      "Starting training step 49 with an exploration rate of 0.020000000000000018\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "random.seed(47)\n",
    "test_data = [lgt.generate_problem(10, 10, random.randrange(2), random.randrange(3), random.randrange(4)) for i in range(100)]\n",
    "\n",
    "trad_agent = WorkingTraditionalAgent()\n",
    "random.seed(0)\n",
    "grids_per_step = 1_000\n",
    "n_steps = 50\n",
    "trad_progress = []\n",
    "\n",
    "def test_agent(agent, test_data = test_data):\n",
    "    scores = Counter()\n",
    "    for problem, solution in test_data:\n",
    "        scores.update([agent.test(problem, solution)])\n",
    "    return scores\n",
    "\n",
    "for j in range(n_steps):\n",
    "    trad_progress.append(test_agent(trad_agent)[0])  # Keep track of the number of grids the agent gets perfectly\n",
    "    # Fully random exploration at the beginning of training, fully follow the real policy at the end\n",
    "    exploration_rate = 1 - j/n_steps\n",
    "    print(f\"Starting training step {j} with an exploration rate of {exploration_rate}\", flush = True)\n",
    "    for i in range(grids_per_step):\n",
    "        problem, solution = lgt.generate_problem(10, 10, random.randrange(2), random.randrange(3), random.randrange(4))\n",
    "        trad_agent.train(problem, solution, exploration_rate = exploration_rate)\n",
    "trad_progress.append(test_agent(trad_agent)[0])\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And testing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final performance:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7_/d7tqnwgs3pb_q_t94nmtckdcx9mz_y/T/ipykernel_49124/2331923233.py:21: UserWarning: Encountered situation where some option lacks training data\n",
      "  warnings.warn(\"Encountered situation where some option lacks training data\")\n",
      "/var/folders/7_/d7tqnwgs3pb_q_t94nmtckdcx9mz_y/T/ipykernel_49124/2331923233.py:18: UserWarning: Encountered situation where all options lack training data, defaulting to 0\n",
      "  warnings.warn(\"Encountered situation where all options lack training data, defaulting to 0\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Counter({np.int64(0): 88,\n",
       "         np.int64(-1): 6,\n",
       "         np.int64(-2): 2,\n",
       "         np.int64(-15): 1,\n",
       "         np.int64(-14): 1,\n",
       "         np.int64(-5): 1,\n",
       "         np.int64(-3): 1})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.title(\"Learning curve\")\n",
    "plt.xlabel(\"Grids trained on\")\n",
    "plt.ylabel(\"Grids filled completely correctly (of 100)\")\n",
    "plt.ylim([0, 100])\n",
    "plt.plot(range(0, n_steps*grids_per_step+1, grids_per_step), trad_progress)\n",
    "\n",
    "print(f\"Final performance:\")\n",
    "display(test_agent(trad_agent))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On this amount of training, our agent is able to get a perfect score in roughly 90% of games. Training for longer improves this (see `line_extending_trad_rl.ipynb`), and probably some tuning of hyperparameters could also help. But for now, let's move on to another way of solving this problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A Neural Player"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For now, see `line_extending_neural.ipynb`. TODO summarize here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3: Learning the Rules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We again work under the agent with a 5x5 view framework. We define a *rule* as a statement of the form \"if this list of cells is filled in and this list of cells is not filled in, fill in the central cell.\" Cells in the cell list are specified as a row and a column in the 5x5 view. A *ruleset* is a list of rules with the semantic \"fill in the central cell if any of these rules say to do so.\" Here, we will develop a context-free grammar that can produce rules, demonstrate the success of an agent with a human-written ruleset in this grammar, then train an agent to play the game with a ruleset as its policy — thus learning rules along the way."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grammar and parsing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is an NLTK grammar that generates rules:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "grammar = CFG.fromstring(\"\"\"\n",
    "    S -> \"if_filled\" CellList \"and_empty\" CellList \"then_activate\"\n",
    "    CellList -> \"[\" Cell \"]\" CellList |\n",
    "    Cell -> \"R\" NonCentralNumber \"C\" AnyNumber | \"R\" CentralNumber \"C\" NonCentralNumber\n",
    "    AnyNumber -> NonCentralNumber | CentralNumber\n",
    "    NonCentralNumber -> \"0\" | \"1\" | \"3\" | \"4\"\n",
    "    CentralNumber -> \"2\"\n",
    "    \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['if_filled [ R 0 C 0 ] [ R 2 C 0 ] and_empty [ R 0 C 0 ] [ R 2 C 0 ] then_activate',\n",
       " 'if_filled [ R 0 C 0 ] [ R 2 C 0 ] and_empty [ R 0 C 0 ] [ R 2 C 1 ] then_activate',\n",
       " 'if_filled [ R 0 C 0 ] [ R 2 C 0 ] and_empty [ R 0 C 0 ] [ R 2 C 3 ] then_activate',\n",
       " 'if_filled [ R 0 C 0 ] [ R 2 C 0 ] and_empty [ R 0 C 0 ] [ R 2 C 4 ] then_activate',\n",
       " 'if_filled [ R 0 C 0 ] [ R 2 C 0 ] and_empty [ R 0 C 0 ] then_activate']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "some_rules = [\" \".join(x) for x in generate(grammar, depth = 6)]\n",
    "display(some_rules[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we have hardcoded the idea that the central cell `[ R 2 C 2 ]` is invalid, but there is no elegant way to encode in the *grammar* that cells should not be duplicated in each list, or that cells that appear in the \"if_filled\" list should not appear in the \"and_empty\" list. In other words, it is possible to have rules that are grammatical but unpragmatic."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is an LL(1) language, so it can be parsed by a recursive descent parser:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  if_filled\n",
      "  (CellList\n",
      "    [\n",
      "    (Cell R (NonCentralNumber 0) C (AnyNumber (NonCentralNumber 0)))\n",
      "    ]\n",
      "    (CellList\n",
      "      [\n",
      "      (Cell R (CentralNumber 2) C (NonCentralNumber 0))\n",
      "      ]\n",
      "      (CellList )))\n",
      "  and_empty\n",
      "  (CellList\n",
      "    [\n",
      "    (Cell R (NonCentralNumber 0) C (AnyNumber (NonCentralNumber 0)))\n",
      "    ]\n",
      "    (CellList\n",
      "      [\n",
      "      (Cell R (CentralNumber 2) C (NonCentralNumber 1))\n",
      "      ]\n",
      "      (CellList )))\n",
      "  then_activate)\n"
     ]
    }
   ],
   "source": [
    "parser = RecursiveDescentParser(grammar)\n",
    "parsed = parser.parse(wordpunct_tokenize(some_rules[1]))\n",
    "print(next(parsed))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we walk the parse tree to \"compile\" the cell lists into Python data structures for further use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'if_filled [ R 0 C 0 ] [ R 2 C 0 ] and_empty [ R 0 C 0 ] [ R 2 C 1 ] then_activate'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "([(0, 0), (2, 0)], [(0, 0), (2, 1)])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def compile_cell(cell: Tree):\n",
    "    _, row, _, col = cell\n",
    "    # row, col at this point might be primitive or composite, but in all cases the number is at the end\n",
    "    return int(row.leaves()[-1]), int(col.leaves()[-1])\n",
    "\n",
    "def compile_cell_list(cl_tree: Tree):\n",
    "    if len(cl_tree) == 0: return []\n",
    "    _, first, _, rest = cl_tree\n",
    "    return [compile_cell(first)] + compile_cell_list(rest)\n",
    "\n",
    "def compile_rule_string(rule_string):\n",
    "    root, = parser.parse(wordpunct_tokenize(rule_string))\n",
    "    _, cl_tree1, _, cl_tree2, _ = root\n",
    "    return compile_cell_list(cl_tree1), compile_cell_list(cl_tree2)\n",
    "\n",
    "display(some_rules[1])\n",
    "display(compile_rule_string(some_rules[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Executing rules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function takes a ruleset in compiled form and executes it on a subgrid:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def execute_ruleset(parsed_ruleset, subgrid):\n",
    "    for (if_filled, and_empty) in parsed_ruleset:\n",
    "        if all([subgrid[row, col] for (row, col) in if_filled]) and all([not subgrid[row, col] for (row, col) in and_empty]):\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "execute_ruleset(\n",
    "    [compile_rule_string(\"if_filled [ R 0 C 0 ] [ R 1 C 1 ] and_empty [ R 4 C 4 ] then_activate\")],\n",
    "    lgt.create_grid(\"\"\"\n",
    "        x - - - -\n",
    "        - x - - -\n",
    "        - - - - -\n",
    "        - - - - -\n",
    "        - - - - -\n",
    "    \"\"\")\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using this, we can directly translate the logic from `HumanAgent` above into the new language and execute it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PredefinedRulesetAgent(RunnableGridAgent):\n",
    "    def __init__(self, ruleset, *, window_rows = 2, window_cols = 2):\n",
    "        super().__init__(window_rows = window_rows, window_cols = window_cols)\n",
    "        self._ruleset = ruleset\n",
    "    def real_policy(self, s):\n",
    "        return execute_ruleset(self._ruleset, s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "predefined_ruleset_agent = PredefinedRulesetAgent([compile_rule_string(s) for s in [\n",
    "            \"if_filled [ R 0 C 2 ] [ R 1 C 2 ] and_empty then_activate\",\n",
    "            \"if_filled [ R 0 C 4 ] [ R 1 C 3 ] and_empty then_activate\",\n",
    "            \"if_filled [ R 2 C 4 ] [ R 2 C 3 ] and_empty then_activate\",\n",
    "            \"if_filled [ R 4 C 4 ] [ R 3 C 3 ] and_empty then_activate\",\n",
    "            \"if_filled [ R 4 C 2 ] [ R 3 C 2 ] and_empty then_activate\",\n",
    "            \"if_filled [ R 4 C 0 ] [ R 3 C 1 ] and_empty then_activate\",\n",
    "            \"if_filled [ R 2 C 0 ] [ R 2 C 1 ] and_empty then_activate\",\n",
    "            \"if_filled [ R 0 C 0 ] [ R 1 C 1 ] and_empty then_activate\"\n",
    "        ]])\n",
    "\n",
    "random.seed(47)\n",
    "for i in range(100):\n",
    "    problem, solution = lgt.generate_problem(10, 10, random.randrange(2), random.randrange(3), random.randrange(4))\n",
    "    assert np.array_equal(predefined_ruleset_agent.run(problem), solution)\n",
    "    assert predefined_ruleset_agent.test(problem, solution) == 0  # equivalently"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that this fully correct ruleset contains only eight rules with two cells each in the \"is_filled\" list and never uses the \"and_empty\" list. It will be interesting to see whether we can automatically learn such a simple ruleset or whether we will come up with something needlessly complicated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning Rules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a simple algorithm to learn a ruleset. First, let a rule be \"harmless\" if it never generates false positives, and let a rule be \"helpful\" in the context of some existing ruleset if adding that rule to the ruleset strictly reduces the number of false negatives on at least one problem. Then the algorithm is:\n",
    "  1. Start with an empty ruleset\n",
    "  2. Repeat the following until 100% accuracy:\n",
    "     1. Generate a random candidate rule (biased towards shorter rules)\n",
    "     2. Assess the candidate's harmlessness and helpfulness by measuring the performance of the ruleset with and without the candidate\n",
    "        1. If the candidate is ever responsible for a false positive, it's not harmless; discard it immediately\n",
    "        2. If the candidate is responsible for even one avoided false negative, it's helpful\n",
    "     3. If the candidate is harmless and helpful, add it to the ruleset\n",
    "\n",
    "Problems I foresee here:\n",
    "  1. It's hard to be completely sure if a rule is harmless — what if its harm comes up in a case we just haven't tested yet?\n",
    "  2. The only thing acting like regularization here is the bias towards shorter rules; there is nothing to prevent overlapping rules from being added.\n",
    "\n",
    "To address 2, maybe there is some \"pruning\" we can do once we have a 100% accurate ruleset, or maybe there is a more sophisticated procedure we can follow where we evaluate several rules at a time and only add the *most* helpful, but let's worry about that later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code to generate random rules biased towards shorter ones:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "if_filled [ R 1 C 1 ] [ R 0 C 1 ] and_empty [ R 4 C 2 ] [ R 1 C 2 ] [ R 3 C 4 ] [ R 2 C 0 ] [ R 1 C 1 ] then_activate\n",
      "if_filled and_empty then_activate\n",
      "if_filled and_empty then_activate\n",
      "if_filled and_empty [ R 0 C 1 ] then_activate\n",
      "if_filled [ R 1 C 4 ] and_empty then_activate\n",
      "if_filled [ R 2 C 3 ] [ R 2 C 4 ] [ R 4 C 4 ] [ R 2 C 1 ] and_empty then_activate\n",
      "if_filled [ R 4 C 0 ] [ R 4 C 2 ] [ R 2 C 0 ] and_empty [ R 1 C 0 ] [ R 0 C 3 ] [ R 4 C 3 ] [ R 4 C 2 ] then_activate\n",
      "if_filled [ R 0 C 0 ] and_empty [ R 2 C 3 ] then_activate\n",
      "if_filled and_empty [ R 3 C 2 ] [ R 4 C 0 ] then_activate\n",
      "if_filled [ R 4 C 3 ] and_empty [ R 4 C 0 ] [ R 0 C 0 ] [ R 1 C 3 ] then_activate\n"
     ]
    }
   ],
   "source": [
    "\"Create a probabilistic CFG where `decay` is the chance of adding another cell to the list at each step\"\n",
    "def create_weighted_grammar(decay):\n",
    "    return PCFG.fromstring(f\"\"\"\n",
    "        S -> \"if_filled\" CellList \"and_empty\" CellList \"then_activate\" [1]\n",
    "        CellList -> \"[\" Cell \"]\" CellList [{decay}] | [{1-decay}]\n",
    "        Cell -> \"R\" NonCentralNumber \"C\" AnyNumber [{20/24}] | \"R\" CentralNumber \"C\" NonCentralNumber [{4/24}]\n",
    "        AnyNumber -> NonCentralNumber [0.8] | CentralNumber [0.2]\n",
    "        NonCentralNumber -> \"0\" [0.25] | \"1\" [0.25] | \"3\" [0.25] | \"4\" [0.25]\n",
    "        CentralNumber -> \"2\" [1]\n",
    "        \"\"\")\n",
    "\n",
    "\"Generate a random sentence from the probabilistic CFG\"\n",
    "def generate_one_probabilistic(pcfg: PCFG, current_nonterminal = None):\n",
    "    if current_nonterminal is None: current_nonterminal = pcfg.start()\n",
    "    current_prods = list(pcfg.productions(lhs = current_nonterminal))\n",
    "    selected_prod = random.choices(current_prods, weights = [prod.prob() for prod in current_prods])[0]\n",
    "    result = []\n",
    "    for fragment in selected_prod.rhs():\n",
    "        result += generate_one_probabilistic(pcfg, fragment) if isinstance(fragment, Nonterminal) else [fragment]\n",
    "    return result\n",
    "\n",
    "random.seed(47)\n",
    "for i in range(10):\n",
    "    print(\" \".join(generate_one_probabilistic(create_weighted_grammar(0.5))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LearningRulesetAgent(TrainableGridAgent):\n",
    "    def __init__(self, *, window_rows = 2, window_cols = 2, random_source = random.random, rule_decay = 0.5, grids_per_rule = 5000):\n",
    "        super().__init__(window_rows = window_rows, window_cols = window_cols, random_source = random_source)\n",
    "        self._weighted_grammar = create_weighted_grammar(rule_decay)\n",
    "        self._ruleset = []\n",
    "        self._grids_per_rule = grids_per_rule\n",
    "        self._regenerate_rule()\n",
    "    \n",
    "    \"Set the `_current_rule` to a new rule\"\n",
    "    def _regenerate_rule(self):\n",
    "        self._current_rule = compile_rule_string(\" \".join(generate_one_probabilistic(self._weighted_grammar)))\n",
    "        self._current_grids_tested = 0\n",
    "        self._current_is_helpful = False\n",
    "    \n",
    "    def set_grid(self, grid):\n",
    "        super().set_grid(grid)\n",
    "        self._original_grid = grid\n",
    "\n",
    "    \"Act based on the current `_ruleset`\"\n",
    "    def real_policy(self, s):\n",
    "        return execute_ruleset(self._ruleset, s)\n",
    "    \n",
    "    \"No exploration policy, we're purely simulating what happens with the actual ruleset\"\n",
    "    def train(self, problem, solution, verbose = False):\n",
    "        self.run(problem)\n",
    "        self.update_model(solution, verbose = verbose)\n",
    "        return self.get_grid()\n",
    "\n",
    "    def update_model(self, solution, verbose = False):\n",
    "        self._current_grids_tested += 1\n",
    "        old_guess = self.get_grid()\n",
    "        # What would have happened if the new rule had been part of the ruleset?\n",
    "        new_guess = PredefinedRulesetAgent(self._ruleset + [self._current_rule]).run(self._original_grid)\n",
    "\n",
    "        old_false_positives = np.count_nonzero(old_guess & ~solution)\n",
    "        if old_false_positives > 0: warnings.warn(\"Encountered a false positive with the existing ruleset\")\n",
    "        new_false_positives = np.count_nonzero(new_guess & ~solution)\n",
    "        if new_false_positives > old_false_positives:  # If harmful, reject immediately\n",
    "            self._regenerate_rule()\n",
    "            return\n",
    "        \n",
    "        old_false_negatives = np.count_nonzero(solution & ~old_guess)\n",
    "        new_false_negatives = np.count_nonzero(solution & ~new_guess)\n",
    "        if new_false_negatives < old_false_negatives:  # If helpful, record but keep checking harmfulness until _grids_per_rule\n",
    "            self._current_is_helpful = True\n",
    "        \n",
    "        if self._current_grids_tested >= self._grids_per_rule:\n",
    "            if self._current_is_helpful:\n",
    "                if verbose: print(f\"Accepting helpful rule: {self._current_rule}\")\n",
    "                self._ruleset.append(self._current_rule)\n",
    "            self._regenerate_rule()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training step 0, currently have 0 rules\n",
      "Starting training step 1, currently have 0 rules\n",
      "Starting training step 2, currently have 0 rules\n",
      "Starting training step 3, currently have 0 rules\n",
      "Starting training step 4, currently have 0 rules\n",
      "Starting training step 5, currently have 0 rules\n",
      "Accepting helpful rule: ([(4, 2), (3, 2)], [])\n",
      "Starting training step 6, currently have 1 rules\n",
      "Starting training step 7, currently have 1 rules\n",
      "Starting training step 8, currently have 1 rules\n",
      "Starting training step 9, currently have 1 rules\n",
      "Accepting helpful rule: ([(2, 3), (0, 0), (2, 4)], [(1, 4), (1, 3), (0, 1), (0, 3), (0, 2)])\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "def training_session(agent, grids_per_step, n_steps):\n",
    "    random.seed(0)\n",
    "    progress = []\n",
    "\n",
    "    for j in range(n_steps):\n",
    "        progress.append(test_agent(agent)[0])  # Keep track of the number of grids the agent gets perfectly\n",
    "        print(f\"Starting training step {j}, currently have {len(agent._ruleset)} rules\", flush = True)\n",
    "        for i in range(grids_per_step):\n",
    "            problem, solution = lgt.generate_problem(10, 10, random.randrange(2), random.randrange(3), random.randrange(4))\n",
    "            agent.train(problem, solution, verbose = True)\n",
    "    progress.append(test_agent(agent)[0])\n",
    "    print(\"Done!\")\n",
    "    return progress\n",
    "\n",
    "rules_agent = LearningRulesetAgent()\n",
    "progress = training_session(rules_agent, 5000, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[([(4, 2), (3, 2)], []),\n",
       " ([(2, 3), (0, 0), (2, 4)], [(1, 4), (1, 3), (0, 1), (0, 3), (0, 2)])]"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rules_agent._ruleset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, it does seem to work, but it's very slow. What if we artificially limit rules to those with two cells in the \"if_filled\" section and zero in the \"and_empty\" section?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training step 0, currently have 0 rules\n",
      "Starting training step 1, currently have 0 rules\n",
      "Accepting helpful rule: ([(4, 2), (3, 2)], [])\n",
      "Starting training step 2, currently have 1 rules\n",
      "Accepting helpful rule: ([(2, 3), (2, 4)], [])\n",
      "Starting training step 3, currently have 2 rules\n",
      "Starting training step 4, currently have 2 rules\n",
      "Starting training step 5, currently have 2 rules\n",
      "Accepting helpful rule: ([(1, 2), (0, 2)], [])\n",
      "Starting training step 6, currently have 3 rules\n",
      "Accepting helpful rule: ([(3, 1), (4, 0)], [])\n",
      "Starting training step 7, currently have 4 rules\n",
      "Starting training step 8, currently have 4 rules\n",
      "Accepting helpful rule: ([(2, 1), (2, 0)], [])\n",
      "Starting training step 9, currently have 5 rules\n",
      "Accepting helpful rule: ([(1, 3), (0, 4)], [])\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "class CheatingRulesetAgent(LearningRulesetAgent):\n",
    "    \"Set the `_current_rule` to a new rule that is more likely to work\"\n",
    "    def _regenerate_rule(self):\n",
    "        rule = ((), ())\n",
    "        while len(rule[0]) != 2 or len(rule[1]) != 0:\n",
    "            rule = compile_rule_string(\" \".join(generate_one_probabilistic(self._weighted_grammar)))\n",
    "        self._current_rule = rule\n",
    "        self._current_grids_tested = 0\n",
    "        self._current_is_helpful = False\n",
    "\n",
    "cheating_rules_agent = CheatingRulesetAgent()\n",
    "progress = training_session(cheating_rules_agent, 5000, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[([(4, 2), (3, 2)], []),\n",
       " ([(2, 3), (2, 4)], []),\n",
       " ([(1, 2), (0, 2)], []),\n",
       " ([(3, 1), (4, 0)], []),\n",
       " ([(2, 1), (2, 0)], []),\n",
       " ([(1, 3), (0, 4)], [])]"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cheating_rules_agent._ruleset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It finds more rules, but not *that* many more rules. This suggests that most of the time is spent validating correct rules rather than rejecting incorrect ones. Okay, back to the non-cheating version and let's just run it for a really long time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training step 0, currently have 0 rules\n",
      "Accepting helpful rule: ([(1, 2), (0, 2)], [(2, 1)])\n",
      "Starting training step 1, currently have 1 rules\n",
      "Starting training step 2, currently have 1 rules\n",
      "Accepting helpful rule: ([(2, 4), (2, 1), (2, 3), (0, 4), (2, 3), (2, 1), (0, 2)], [(1, 0)])\n",
      "Starting training step 3, currently have 2 rules\n",
      "Starting training step 4, currently have 2 rules\n",
      "Starting training step 5, currently have 2 rules\n",
      "Accepting helpful rule: ([(2, 4), (4, 0), (3, 1)], [])\n",
      "Starting training step 6, currently have 3 rules\n",
      "Accepting helpful rule: ([(0, 0), (1, 1)], [])\n",
      "Starting training step 7, currently have 4 rules\n",
      "Starting training step 8, currently have 4 rules\n",
      "Starting training step 9, currently have 4 rules\n",
      "Starting training step 10, currently have 4 rules\n",
      "Accepting helpful rule: ([(3, 2), (3, 4), (4, 2)], [(4, 1)])\n",
      "Starting training step 11, currently have 5 rules\n",
      "Starting training step 12, currently have 5 rules\n",
      "Starting training step 13, currently have 5 rules\n",
      "Accepting helpful rule: ([(3, 3), (4, 4)], [])\n",
      "Accepting helpful rule: ([(2, 3), (2, 4)], [(2, 0), (4, 3)])\n",
      "Starting training step 14, currently have 7 rules\n",
      "Starting training step 15, currently have 7 rules\n",
      "Starting training step 16, currently have 7 rules\n",
      "Starting training step 17, currently have 7 rules\n",
      "Accepting helpful rule: ([(4, 0), (3, 1)], [])\n",
      "Starting training step 18, currently have 8 rules\n",
      "Accepting helpful rule: ([(3, 2), (4, 2)], [(3, 1)])\n",
      "Starting training step 19, currently have 9 rules\n",
      "Starting training step 20, currently have 9 rules\n",
      "Starting training step 21, currently have 9 rules\n",
      "Starting training step 22, currently have 9 rules\n",
      "Accepting helpful rule: ([(1, 3), (0, 4)], [(2, 4), (3, 3)])\n",
      "Starting training step 23, currently have 10 rules\n",
      "Starting training step 24, currently have 10 rules\n",
      "Starting training step 25, currently have 10 rules\n",
      "Starting training step 26, currently have 10 rules\n",
      "Starting training step 27, currently have 10 rules\n",
      "Starting training step 28, currently have 10 rules\n",
      "Starting training step 29, currently have 10 rules\n",
      "Starting training step 30, currently have 10 rules\n",
      "Starting training step 31, currently have 10 rules\n",
      "Starting training step 32, currently have 10 rules\n",
      "Starting training step 33, currently have 10 rules\n",
      "Starting training step 34, currently have 10 rules\n",
      "Starting training step 35, currently have 10 rules\n",
      "Starting training step 36, currently have 10 rules\n",
      "Starting training step 37, currently have 10 rules\n",
      "Starting training step 38, currently have 10 rules\n",
      "Accepting helpful rule: ([(2, 0), (4, 4), (2, 1)], [])\n",
      "Starting training step 39, currently have 11 rules\n",
      "Starting training step 40, currently have 11 rules\n",
      "Starting training step 41, currently have 11 rules\n",
      "Starting training step 42, currently have 11 rules\n",
      "Accepting helpful rule: ([(2, 0), (2, 1)], [(0, 4), (2, 4)])\n",
      "Starting training step 43, currently have 12 rules\n",
      "Starting training step 44, currently have 12 rules\n",
      "Accepting helpful rule: ([(0, 4), (1, 3)], [])\n",
      "Starting training step 45, currently have 13 rules\n",
      "Starting training step 46, currently have 13 rules\n",
      "Starting training step 47, currently have 13 rules\n",
      "Starting training step 48, currently have 13 rules\n",
      "Starting training step 49, currently have 13 rules\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "long_rules_agent = LearningRulesetAgent()\n",
    "progress = training_session(long_rules_agent, 25_000, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[([(1, 2), (0, 2)], [(2, 1)]),\n",
       " ([(2, 4), (2, 1), (2, 3), (0, 4), (2, 3), (2, 1), (0, 2)], [(1, 0)]),\n",
       " ([(2, 4), (4, 0), (3, 1)], []),\n",
       " ([(0, 0), (1, 1)], []),\n",
       " ([(3, 2), (3, 4), (4, 2)], [(4, 1)]),\n",
       " ([(3, 3), (4, 4)], []),\n",
       " ([(2, 3), (2, 4)], [(2, 0), (4, 3)]),\n",
       " ([(4, 0), (3, 1)], []),\n",
       " ([(3, 2), (4, 2)], [(3, 1)]),\n",
       " ([(1, 3), (0, 4)], [(2, 4), (3, 3)]),\n",
       " ([(2, 0), (4, 4), (2, 1)], []),\n",
       " ([(2, 0), (2, 1)], [(0, 4), (2, 4)]),\n",
       " ([(0, 4), (1, 3)], [])]"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "long_rules_agent._ruleset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO it's a little worrying that `long_rules_agent` doesn't start with the same first two rules as `rules_agent` even though we're setting the random seed, track down the nondeterminism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final performance:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Counter({np.int64(0): 94, np.int64(-2): 3, np.int64(-3): 3})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.title(\"Learning curve\")\n",
    "plt.xlabel(\"Grids trained on\")\n",
    "plt.ylabel(\"Grids filled completely correctly (of 100)\")\n",
    "plt.ylim([0, 100])\n",
    "plt.plot(range(0, 50*25_000+1, 25_000), progress)\n",
    "\n",
    "print(f\"Final performance:\")\n",
    "display(test_agent(long_rules_agent))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It took quite a while, but we have pretty good accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How redundant are the rules in the ruleset? Here is a visualization of the ruleset where each rule is a 5x5 grid with the \"is_filled\" cells as `x` and the \"and_empty\" cells as `o`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- - x - -    - - x - x    - - - - -    x - - - -    - - - - -\n",
      "- - x - -    o - - - -    - - - - -    - x - - -    - - - - -\n",
      "- o - - -    - x - x x    - - - - x    - - - - -    - - - - -\n",
      "- - - - -    - - - - -    - x - - -    - - - - -    - - x - x\n",
      "- - - - -    - - - - -    x - - - -    - - - - -    - o x - -\n",
      "\n",
      "- - - - -    - - - - -    - - - - -    - - - - -    - - - - x\n",
      "- - - - -    - - - - -    - - - - -    - - - - -    - - - x -\n",
      "- - - - -    o - - x x    - - - - -    - - - - -    - - - - o\n",
      "- - - x -    - - - - -    - x - - -    - o x - -    - - - o -\n",
      "- - - - x    - - - o -    x - - - -    - - x - -    - - - - -\n",
      "\n",
      "- - - - -    - - - - o    - - - - x\n",
      "- - - - -    - - - - -    - - - x -\n",
      "x x - - -    x x - - o    - - - - -\n",
      "- - - - -    - - - - -    - - - - -\n",
      "- - - - x    - - - - -    - - - - -\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"Create a grid of -, x, and o to represent a given rule (represented in compiled form)\"\n",
    "def viz_rule(compiled_rule, rows = 5, cols = 5):\n",
    "    is_filled, and_empty = compiled_rule\n",
    "    char_grid = np.full((rows, cols), \"-\")\n",
    "    for idx in is_filled: char_grid[idx] = \"x\"\n",
    "    for idx in and_empty: char_grid[idx] = \"o\"\n",
    "    return char_grid\n",
    "\n",
    "\"Use `viz_rule` to visualize a compiled ruleset. Displays `display_cols` grids side by side on each row\"\n",
    "def viz_ruleset(compiled_ruleset, subgrid_rows = 5, subgrid_cols = 5, display_cols = 5):\n",
    "    rule_grids = [viz_rule(compiled_rule, subgrid_rows, subgrid_cols) for compiled_rule in compiled_ruleset]\n",
    "    for grid_start_i in range(0, len(rule_grids), display_cols):\n",
    "        for row_i in range(subgrid_rows):\n",
    "            this_row = [\" \".join(this_grid[row_i]) for this_grid in rule_grids[grid_start_i:grid_start_i+display_cols]]\n",
    "            print(\"    \".join(this_row))\n",
    "        print()\n",
    "\n",
    "viz_ruleset(long_rules_agent._ruleset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can at least verify that all the rules are harmless, so problem 1 is less of an issue than I thought. It looks like at least one rule implies a superset of moves of another — a manifestation of problem 2 — which suggests that a pruning process would indeed be helpful."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For reference, here's our manual, ideal ruleset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- - x - -    - - - - x    - - - - -    - - - - -    - - - - -\n",
      "- - x - -    - - - x -    - - - - -    - - - - -    - - - - -\n",
      "- - - - -    - - - - -    - - - x x    - - - - -    - - - - -\n",
      "- - - - -    - - - - -    - - - - -    - - - x -    - - x - -\n",
      "- - - - -    - - - - -    - - - - -    - - - - x    - - x - -\n",
      "\n",
      "- - - - -    - - - - -    x - - - -\n",
      "- - - - -    - - - - -    - x - - -\n",
      "- - - - -    x x - - -    - - - - -\n",
      "- x - - -    - - - - -    - - - - -\n",
      "x - - - -    - - - - -    - - - - -\n",
      "\n"
     ]
    }
   ],
   "source": [
    "viz_ruleset([compile_rule_string(s) for s in [\n",
    "            \"if_filled [ R 0 C 2 ] [ R 1 C 2 ] and_empty then_activate\",\n",
    "            \"if_filled [ R 0 C 4 ] [ R 1 C 3 ] and_empty then_activate\",\n",
    "            \"if_filled [ R 2 C 4 ] [ R 2 C 3 ] and_empty then_activate\",\n",
    "            \"if_filled [ R 4 C 4 ] [ R 3 C 3 ] and_empty then_activate\",\n",
    "            \"if_filled [ R 4 C 2 ] [ R 3 C 2 ] and_empty then_activate\",\n",
    "            \"if_filled [ R 4 C 0 ] [ R 3 C 1 ] and_empty then_activate\",\n",
    "            \"if_filled [ R 2 C 0 ] [ R 2 C 1 ] and_empty then_activate\",\n",
    "            \"if_filled [ R 0 C 0 ] [ R 1 C 1 ] and_empty then_activate\"\n",
    "        ]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
