{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Line Extending Game 0\n",
    "Here, we:\n",
    "1. Introduce the \"two-pixel line extending game\"\n",
    "2. Use reinforcement learning to learn to play the game\n",
    "3. Use reinforcement learning to learn *rules* to play the game\n",
    "\n",
    "Throughout the notebook, helper functions whose implementations are not important are factored out into a library file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import warnings\n",
    "import time\n",
    "from collections import Counter\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from nsai_experiments import line_extending_game_tools as lgt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1: The two-pixel line extending game"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imagine a NxN grid of pixels that can either be on (`x`) or off (`-`), represented by a NumPy Boolean array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[False False False False False]\n",
      " [ True False False False False]\n",
      " [ True False False  True False]\n",
      " [False False  True False False]\n",
      " [False False False False False]]\n",
      "- - - - -\n",
      "x - - - -\n",
      "x - - x -\n",
      "- - x - -\n",
      "- - - - -\n"
     ]
    }
   ],
   "source": [
    "sample_grid = lgt.create_grid(\"\"\"\n",
    "    - - - - -\n",
    "    x - - - -\n",
    "    x - - x -\n",
    "    - - x - -\n",
    "    - - - - -\n",
    "    \"\"\")\n",
    "print(sample_grid)\n",
    "lgt.display_grid(sample_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The game is: for every \"line segment\" consisting of at least two contiguous `x`s, extend the segment all the way across the grid. For instance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- - - - - - - - - -\n",
      "- - x - - x - - - -\n",
      "- x - - x - - - - -\n",
      "- - - - - - - - - -\n",
      "- - - - - - - - - -\n",
      "- - - - - - - - - -\n",
      "- - - - - - - - - -\n",
      "- - - - - - - - - -\n",
      "- - - - - - - x x -\n",
      "- - - - - - - - - -\n",
      "\n",
      "- - - x - - x - - -\n",
      "- - x - - x - - - -\n",
      "- x - - x - - - - -\n",
      "x - - x - - - - - -\n",
      "- - x - - - - - - -\n",
      "- x - - - - - - - -\n",
      "x - - - - - - - - -\n",
      "- - - - - - - - - -\n",
      "x x x x x x x x x x\n",
      "- - - - - - - - - -\n"
     ]
    }
   ],
   "source": [
    "sample_start1 = lgt.create_grid(\"\"\"\n",
    "    - - - - - - - - - - \n",
    "    - - x - - x - - - - \n",
    "    - x - - x - - - - - \n",
    "    - - - - - - - - - - \n",
    "    - - - - - - - - - - \n",
    "    - - - - - - - - - - \n",
    "    - - - - - - - - - - \n",
    "    - - - - - - - - - - \n",
    "    - - - - - - - x x - \n",
    "    - - - - - - - - - - \n",
    "    \"\"\")\n",
    "\n",
    "sample_final1 = lgt.create_grid(\"\"\"\n",
    "    - - - x - - x - - - \n",
    "    - - x - - x - - - - \n",
    "    - x - - x - - - - - \n",
    "    x - - x - - - - - - \n",
    "    - - x - - - - - - - \n",
    "    - x - - - - - - - - \n",
    "    x - - - - - - - - - \n",
    "    - - - - - - - - - - \n",
    "    x x x x x x x x x x \n",
    "    - - - - - - - - - -  \n",
    "    \"\"\")\n",
    "\n",
    "lgt.display_grid(sample_start1)\n",
    "print()\n",
    "lgt.display_grid(sample_final1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The game is played in moves, where each move consists of changing one `-` to an `x`. For simplicity in this very basic version of the game, we disallow starting states that correspond to final states containing line segments not part of a line. For instance, this is disallowed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- - - - - - - - - -\n",
      "- - x - - - - - - -\n",
      "- - x - - - - - - -\n",
      "- - - - - - - - - -\n",
      "- - - - - - - - - -\n",
      "- - - - - - - - - -\n",
      "- - - - - - - - - -\n",
      "- - - - - - - - - -\n",
      "- - - - - - x x - -\n",
      "- - - - - - - - - -\n",
      "\n",
      "- - x - - - - - - -\n",
      "- - x - - - - - - -\n",
      "- - x - - - - - - -\n",
      "- - x - - - - - - -\n",
      "- - x - - - - - - -\n",
      "- - x - - - - - - -\n",
      "- - x - - - - - - -\n",
      "- - x - - - - - - -\n",
      "x x x x x x x x x x\n",
      "- - x - - - - - - -\n"
     ]
    }
   ],
   "source": [
    "bad_start = lgt.create_grid(\"\"\"\n",
    "    - - - - - - - - - -\n",
    "    - - x - - - - - - -\n",
    "    - - x - - - - - - -\n",
    "    - - - - - - - - - -\n",
    "    - - - - - - - - - -\n",
    "    - - - - - - - - - -\n",
    "    - - - - - - - - - -\n",
    "    - - - - - - - - - -\n",
    "    - - - - - - x x - -\n",
    "    - - - - - - - - - -\n",
    "    \"\"\")\n",
    "\n",
    "bad_final = lgt.create_grid(\"\"\"\n",
    "    - - x - - - - - - -\n",
    "    - - x - - - - - - -\n",
    "    - - x - - - - - - -\n",
    "    - - x - - - - - - -\n",
    "    - - x - - - - - - -\n",
    "    - - x - - - - - - -\n",
    "    - - x - - - - - - -\n",
    "    - - x - - - - - - -\n",
    "    x x x x x x x x x x\n",
    "    - - x - - - - - - -\n",
    "    \"\"\")\n",
    "\n",
    "lgt.display_grid(bad_start)\n",
    "print()\n",
    "lgt.display_grid(bad_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "because its final state contains several diagonal line segments not part of lines. For the two-pixel version, this means that, with a few exceptions, lines cannot touch each other. This rule gives our game the useful property that if grid A can be transformed into grid B with one move, a solution for grid B plus that one move is a solution for grid A."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A Human Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this convenient modification, an intuitive solution to the game is: whenever you see a line segment, extend it on one of the ends if possible; repeat until no more moves are possible; then the game is solved. Here's an implementation of that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- - - - - - - - - -\n",
      "- - x - - x - - - -\n",
      "- x - - x - - - - -\n",
      "- - - - - - - - - -\n",
      "- - - - - - - - - -\n",
      "- - - - - - - - - -\n",
      "- - - - - - - - - -\n",
      "- - - - - - - - - -\n",
      "- - - - - - - x x -\n",
      "- - - - - - - - - -\n",
      "6 initial possible moves... down to 6 due to out of bounds... down to 6 due to already filled in\n",
      "8 initial possible moves... down to 7 due to out of bounds... down to 5 due to already filled in\n",
      "10 initial possible moves... down to 9 due to out of bounds... down to 5 due to already filled in\n",
      "12 initial possible moves... down to 11 due to out of bounds... down to 5 due to already filled in\n",
      "14 initial possible moves... down to 12 due to out of bounds... down to 4 due to already filled in\n",
      "16 initial possible moves... down to 14 due to out of bounds... down to 4 due to already filled in\n",
      "18 initial possible moves... down to 15 due to out of bounds... down to 3 due to already filled in\n",
      "20 initial possible moves... down to 16 due to out of bounds... down to 2 due to already filled in\n",
      "22 initial possible moves... down to 18 due to out of bounds... down to 2 due to already filled in\n",
      "24 initial possible moves... down to 19 due to out of bounds... down to 1 due to already filled in\n",
      "26 initial possible moves... down to 21 due to out of bounds... down to 1 due to already filled in\n",
      "28 initial possible moves... down to 23 due to out of bounds... down to 1 due to already filled in\n",
      "30 initial possible moves... down to 25 due to out of bounds... down to 1 due to already filled in\n",
      "32 initial possible moves... down to 27 due to out of bounds... down to 1 due to already filled in\n",
      "34 initial possible moves... down to 29 due to out of bounds... down to 1 due to already filled in\n",
      "36 initial possible moves... down to 30 due to out of bounds... down to 0 due to already filled in\n",
      "Success after 16 iterations!\n",
      "- - - x - - x - - -\n",
      "- - x - - x - - - -\n",
      "- x - - x - - - - -\n",
      "x - - x - - - - - -\n",
      "- - x - - - - - - -\n",
      "- x - - - - - - - -\n",
      "x - - - - - - - - -\n",
      "- - - - - - - - - -\n",
      "x x x x x x x x x x\n",
      "- - - - - - - - - -\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Takes a segment and direction and outputs the coordinates of the points on each end of the\n",
    "segment that we'd want to extend\n",
    "\"\"\"\n",
    "def where_to_extend(segment, direction):\n",
    "    (a, b), (c, d) = segment\n",
    "    match direction:\n",
    "        case \"HORIZONTAL\": return (a, b-1), (c, d+1)\n",
    "        case \"VERTICAL\":   return (a-1, b), (c+1, d)\n",
    "        case \"SLOPE_DOWN\": return (a-1, b-1), (c+1, d+1)\n",
    "        case \"SLOPE_UP\":   return (a+1, b-1), (c-1, d+1)\n",
    "\n",
    "def solve_human(unsolved_problem, timeout = 100, random_seed = 47, print_status = False):\n",
    "    random.seed(random_seed)\n",
    "    rows, cols = np.shape(unsolved_problem)\n",
    "    answer = np.copy(unsolved_problem)\n",
    "    # Each iteration is a move in the game; note that we only need to refer to the current state (not the starting state) to find the next move\n",
    "    for i in range(timeout):\n",
    "        # Find all possible line segments and the points we'd want to fill in to extend those segments\n",
    "        segments, directions = lgt.find_all_segments(answer)\n",
    "        possible_moves = [point\n",
    "                              for (segment, direction) in zip(segments, directions)\n",
    "                                  for point in where_to_extend(segment, direction)]\n",
    "        \n",
    "        # Exclude points that are off the board and points that have already been filled in\n",
    "        if print_status: print(f\"{len(possible_moves)} initial possible moves... \", end = \"\")\n",
    "        possible_moves = list(filter(lambda point: 0 <= point[0] < rows and 0 <= point[1] < cols, possible_moves))\n",
    "        if print_status: print(f\"down to {len(possible_moves)} due to out of bounds... \", end = \"\")\n",
    "        possible_moves = list(filter(lambda point: not answer[point[0], point[1]], possible_moves))\n",
    "        if print_status: print(f\"down to {len(possible_moves)} due to already filled in\")\n",
    "        \n",
    "        # End or choose a random move from the possible points\n",
    "        if len(possible_moves) == 0:\n",
    "            if print_status: print(f\"Success after {i+1} iterations!\")\n",
    "            return answer\n",
    "        my_move = random.choice(possible_moves)\n",
    "        answer[my_move] = True\n",
    "    if print_status: print(f\"Timed out after {timeout} iterations\")\n",
    "    return answer\n",
    "\n",
    "lgt.display_grid(sample_start1)\n",
    "human_answer = solve_human(sample_start1, print_status = True)\n",
    "lgt.display_grid(human_answer)\n",
    "\n",
    "assert np.array_equal(human_answer, sample_final1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obviously this is not the most efficient solution — we are starting completely from scratch every iteration and, for most of the game, most of the candidate moves are already filled in — but it is easy to understand. Let's generate some (problem, solution) pairs and test that the algorithm works:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- - - - - - - - - -\n",
      "- - x - - - - x - -\n",
      "- x - x - - - - - x\n",
      "x - - - - - - - x -\n",
      "- - - - - - - x - -\n",
      "- - - - - - x - - -\n",
      "- x - - - - - x - -\n",
      "- - - - - - - - - -\n",
      "- - - - - - - - - -\n",
      "- - - - - - - - - -\n"
     ]
    }
   ],
   "source": [
    "lgt.display_grid(lgt.generate_problem(10, 10, 2, 2, 2)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(47)\n",
    "for i in range(100):\n",
    "    # Generate a problem with the given dimensions and number of three-length segments,\n",
    "    # two-length features, and one-length features; and the corresponding solution\n",
    "    problem, solution = lgt.generate_problem(10, 10, random.randrange(2), random.randrange(3), random.randrange(4))\n",
    "    assert np.array_equal(solve_human(problem), solution)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2: A Reinforcement Learning Player\n",
    "Now let's use traditional reinforcement learning to teach an agent how to play the game. The development of this RL agent turned out to require some iteration, so I factored that process out into `line_extending_trad_rl.ipynb`. Here, I'll describe the more or less successful design I ended up with."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We imagine an agent moving around the board, turning on all the pixels it deems necessary in a certain area before moving on. We'll give the agent a \"view\" of a 5x5 square centered on the active pixel (thereby encoding \"for free\" the knowledge that what to do for each pixel depends only on the values of pixels a maximum of 2 pixels away) and let it make two actions: turn on the pixel or move to the next cell. We'll also give the agent for free that it is not possible to activate a pixel that is already activated. We will drag this agent across the entire board until it makes a full pass without activating any pixels.\n",
    "\n",
    "The agent's policy is represented by a table where the rows are each possible state — all $2^{5*5-1} = 16,777,216$ of them — the columns are each possible action — either fill in the active pixel or move on — and the values are the quality of taking that action given that state. (In practice, we'll use two tables so that we can normalize values by the number of times they were trained.) For training, we'll use an exploration policy that initially makes random decisions biased towards the \"move on\" action and starts to follow the real policy closer and closer as training proceeds. We'll consider the training agent done with a given grid when it has activated the same number of pixels as are activated in the answer and then made a full pass over the grid after that. We will then compare the agent-generated grid to the solution grid and use the value of each pixel to update the decisions that influenced that pixel.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Created from the successful agent we ended up with in `line_extending_trad_rl.ipynb`\n",
    "class WorkingTraditionalAgent:\n",
    "    \"\"\"\n",
    "    Initialize the agent for a grid with `n_rows` rows and `n_cols` cols; give it a state\n",
    "    window of height `window_rows*2+1` and width `window_cols*2+1`; call `random_source` for\n",
    "    a source of randomness.\n",
    "    \"\"\"\n",
    "    def __init__(self, *, window_rows = 2, window_cols = 2, random_source = random.random):\n",
    "        self._window_rows = window_rows\n",
    "        self._window_cols = window_cols\n",
    "        self._random_source = random_source\n",
    "        # PERF might be better to store these together for better caching performance\n",
    "        # Rows are state, cols are action (0 = move on, 1 = fill in), vals are q-value numerator\n",
    "        self._q_table = np.zeros((2**((window_rows*2+1)*(window_cols*2+1)-1), 2), dtype=np.int64)\n",
    "        # Rows are state, cols are action, vals are # of times encountered in training data\n",
    "        self._times_encountered = np.zeros_like(self._q_table)\n",
    "        self._cells_traversed = 0\n",
    "    \n",
    "    \"\"\"\n",
    "    Set the grid that the agent operates on; place the agent at the top left corner. Creates\n",
    "    a copy of the grid; subsequent operations will not mutate the original.\n",
    "    \"\"\"\n",
    "    def set_grid(self, grid):\n",
    "        self._n_rows, self._n_cols = grid.shape\n",
    "        # Probability of moving on during exploration. Chosen so that 10% of cells\n",
    "        # are filled in after max(n_rows, n_cols) full passes over the grid\n",
    "        self._exploration_bias = 1 - 0.1/max(self._n_rows, self._n_cols)\n",
    "        assert np.shape(grid) == (self._n_rows, self._n_cols)\n",
    "        self._padded_grid = np.pad(grid, ((self._window_rows, self._window_rows), (self._window_cols, self._window_cols)))\n",
    "        self._my_row = 0\n",
    "        self._my_col = 0\n",
    "        self._actions_taken = []\n",
    "        self._action_locations = []\n",
    "\n",
    "    \"Mark the current cell as on\"\n",
    "    def activate_current_cell(self):\n",
    "        self._padded_grid[self._window_rows+self._my_row, self._window_cols+self._my_col] = True\n",
    "\n",
    "    \"Read the current cell\"\n",
    "    def read_current_cell(self):\n",
    "        return self._padded_grid[self._window_rows+self._my_row, self._window_cols+self._my_col]\n",
    "    \n",
    "    \"Get the grid with whatever modifications the agent has made to it so far\"\n",
    "    def get_grid(self):\n",
    "        return self._padded_grid[self._window_rows:-self._window_rows, self._window_cols:-self._window_cols]\n",
    "    \n",
    "    \"Count the total number of filled cells in the current grid\"\n",
    "    def count_filled_cells(self):\n",
    "        return np.sum(self.get_grid())\n",
    "    \n",
    "    \"Get the current agent state as a grid centered on the active cell (which is technically not part of the state)\"\n",
    "    def current_state_grid(self):\n",
    "        return self._padded_grid[\n",
    "            self._my_row:self._my_row+self._window_rows*2+1,\n",
    "            self._my_col:self._my_col+self._window_cols*2+1]\n",
    "    \n",
    "    \"Use binary to encode the current agent state as an integer for `q_table` indexing\"\n",
    "    def _state_grid_to_n(self, state_grid):\n",
    "        tr, tc = self._window_rows*2+1, self._window_cols*2+1\n",
    "        assert np.shape(state_grid) == (tr, tc)\n",
    "        # Remove the center cell, which is not part of the state\n",
    "        # PERF could do this afterwards with bit twiddling\n",
    "        without_center_cell = np.delete(state_grid.flatten(), tc*self._window_rows+self._window_cols)\n",
    "        return without_center_cell.dot(2**np.arange(tr*tc-1)[::-1])\n",
    "    \n",
    "    \"Apply the exploration policy to the state grid `s` to produce an action\"\n",
    "    def exploration_policy(self, s):\n",
    "        if self._random_source() < self._exploration_rate:\n",
    "            return int(self._random_source() >= self._exploration_bias)\n",
    "        return self.real_policy(s)\n",
    "    \n",
    "    \"Apply the real policy to the state grid `s` to produce an action\"\n",
    "    def real_policy(self, s):\n",
    "        idx = self._state_grid_to_n(s)\n",
    "        q_row = self._q_table[idx]\n",
    "        te_row = self._times_encountered[idx]\n",
    "        with np.errstate(invalid = \"ignore\"): q_quotient = q_row/te_row\n",
    "        if len(q_quotient[np.isnan(q_quotient)]) == len(q_quotient):\n",
    "            warnings.warn(\"Encountered situation where all options lack training data, defaulting to 0\")\n",
    "            return 0\n",
    "        elif len(q_quotient[np.isnan(q_quotient)]) > 0:\n",
    "            warnings.warn(\"Encountered situation where some option lacks training data\")\n",
    "            q_quotient[np.isnan(q_quotient)] = -np.inf  # Never choose the option that hasn't been trained\n",
    "        return np.argmax(q_quotient)\n",
    "    \n",
    "    \"Move the agent to its next position on the board; wrap around at the end\"\n",
    "    def increment_position(self):\n",
    "        self._my_col += 1\n",
    "        if self._my_col >= self._n_cols:\n",
    "            self._my_row += 1\n",
    "            self._my_col = 0\n",
    "        if self._my_row >= self._n_rows:\n",
    "            self._my_row = 0\n",
    "        self._cells_traversed += 1\n",
    "    \n",
    "    \"Perform a step either with the exploration policy or the real policy\"\n",
    "    def step(self, real, verbose = False):\n",
    "        policy = self.real_policy if real else self.exploration_policy\n",
    "        state = self.current_state_grid()\n",
    "        \n",
    "        # If the current cell is already filled in, move on without consulting the policy\n",
    "        if self.read_current_cell():\n",
    "            action = 0\n",
    "            if verbose: print(\"Moving on as active cell is already filled in\")\n",
    "        else:\n",
    "            action = policy(state)\n",
    "            self._actions_taken.append((self._state_grid_to_n(state), action))\n",
    "            self._action_locations.append((self._my_row, self._my_col))  # surprise tool that will help us later\n",
    "            if verbose: print(f\"Policy evaluates to action {action}\")\n",
    "        \n",
    "        if action:\n",
    "            self.activate_current_cell()\n",
    "        else:\n",
    "            self.increment_position()\n",
    "        if verbose: print(f\"Position is now {(self._my_row, self._my_col)}\")\n",
    "        return action\n",
    "    \n",
    "    \"Get the number of cells traversed so far\"\n",
    "    def get_cells_traversed(self):\n",
    "        return self._cells_traversed\n",
    "    \n",
    "    \"Provide a single number that captures how well we did against a true answer grid\"\n",
    "    def evaluate_goodness(self, answer_grid):\n",
    "        # A cell counts against us if its true value differs from the predicted value -- that's xor\n",
    "        return -np.sum(np.abs(answer_grid ^ self.get_grid()))\n",
    "    \n",
    "    \"Update weights based on how our solution differs from the true solution\"\n",
    "    def update_q(self, solution, *, pass_reward = 10, pass_penalty = -1, fill_reward = 100, fill_penalty = -100):\n",
    "        self._normalized_q = None\n",
    "        actions_taken = np.array(self._actions_taken)  # Two columns: _state_grid_to_n, action (0 or 1)\n",
    "        action_locations = np.array(self._action_locations)  # Two columns: row, col\n",
    "        for irow in range(self._n_rows):\n",
    "            for icol in range(self._n_cols):\n",
    "                # All the decisions that happened at this cell (two columns: state n, action)\n",
    "                relevant_actions = actions_taken[(action_locations[:, 0] == irow) & (action_locations[:, 1] == icol)]\n",
    "                yes_indices = relevant_actions[:, 0][relevant_actions[:, 1] == 1]  # state ns where action is 0\n",
    "                no_indices = relevant_actions[:, 0][relevant_actions[:, 1] == 0]  # state ns where action is 1\n",
    "                predicted = self.get_grid()[irow, icol]\n",
    "                actual = solution[irow, icol]\n",
    "                match (predicted, actual):\n",
    "                    case (np.True_, np.False_):  # false positive\n",
    "                        # If we said yes and real was no, reward all nos, penalize the yes\n",
    "                        self._q_table[no_indices, 0] += pass_reward\n",
    "                        self._q_table[yes_indices, 1] += fill_penalty\n",
    "                        self._times_encountered[no_indices, 0] += 1\n",
    "                        self._times_encountered[yes_indices, 1] += 1\n",
    "                    case (np.True_, np.True_):  # true positive\n",
    "                        # If we said yes and real was yes, nothing for nos, reward the yes\n",
    "                        self._q_table[yes_indices, 1] += fill_reward\n",
    "                        self._times_encountered[yes_indices, 1] += 1\n",
    "                    case (np.False_, np.False_):  # true negative\n",
    "                        # If we said no and real was no, reward all nos, there is no yes\n",
    "                        self._q_table[no_indices, 0] += pass_reward\n",
    "                        self._times_encountered[no_indices, 0] += 1\n",
    "                    case (np.False_, np.True_):  # false negative\n",
    "                        # If we said no and real was yes, penalize all nos, there is no yes\n",
    "                        self._q_table[no_indices, 0] += pass_penalty\n",
    "                        self._times_encountered[no_indices, 0] += 1\n",
    "                    case _:\n",
    "                        assert False, \"Failed to match any case\"\n",
    "    \n",
    "    \"\"\"\n",
    "    Set the agent lose on the grid `problem` using the exploration policy with the given\n",
    "    `exploration_rate`; use the grid `solution` to update the weights\n",
    "    \"\"\"\n",
    "    def train(self, problem, solution, exploration_rate = 1.0, verbose = False):\n",
    "        self.set_grid(problem)\n",
    "        self._exploration_rate = exploration_rate\n",
    "        while self.count_filled_cells() < np.sum(solution):\n",
    "            self.step(False)\n",
    "        for i in range(self._n_rows*self._n_cols):\n",
    "            self.step(False)\n",
    "        if verbose:\n",
    "            print(f\"Completed in {self._cells_traversed} steps with {len(self._actions_taken)} exploratory actions taken\")\n",
    "            print(f\"{np.count_nonzero(self.get_grid() == solution)} matches out of {self._n_rows*self._n_cols}\")\n",
    "        self.update_q(solution)\n",
    "        return self.get_grid()\n",
    "    \n",
    "    \"\"\"\n",
    "    Run the agent on the grid `problem` using the real policy; stop when the agent has made\n",
    "    a full pass over the grid without filling any cells or when `timeout` steps have been\n",
    "    made\n",
    "    \"\"\"\n",
    "    def run(self, problem, timeout = 100_000):\n",
    "        self.set_grid(problem)\n",
    "        n_cells = self._n_rows*self._n_cols\n",
    "        i_last_updated = -1\n",
    "        filled_cells = self.count_filled_cells()\n",
    "        for i in range(timeout):\n",
    "            self.step(True)\n",
    "            new_filled_cells = self.count_filled_cells()\n",
    "            if new_filled_cells > filled_cells:\n",
    "                i_last_updated = i\n",
    "            if i-i_last_updated >= n_cells:\n",
    "                return self.get_grid()\n",
    "            filled_cells = new_filled_cells\n",
    "        warnings.warn(\"Run timed out without finishing\")\n",
    "        return self.get_grid()\n",
    "    \n",
    "    \"`run` the agent and return its performance\"\n",
    "    def test(self, problem, solution, timeout = 100_000):\n",
    "        self.run(problem, timeout = timeout)\n",
    "        return self.evaluate_goodness(solution)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To see how this works, we'll feed the agent a fake source of randomness to control its behavior:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "def fake_random_source(l):\n",
    "    it = iter(l)\n",
    "    return lambda: next(it)\n",
    "\n",
    "r = fake_random_source([0.0, 1.0])\n",
    "print(r())\n",
    "print(r())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So if we train it like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed in 75 steps with 68 exploratory actions taken\n",
      "30 matches out of 36\n",
      "x x x x - -\n",
      "- x - - - -\n",
      "- - x - - -\n",
      "- - - - - -\n",
      "- - - - - -\n",
      "- - - - - -\n"
     ]
    }
   ],
   "source": [
    "test_grid = lgt.create_grid(\"\"\"\n",
    "    - - - - - -\n",
    "    - x - - - -\n",
    "    - - x - - -\n",
    "    - - - - - -\n",
    "    - - - - - -\n",
    "    - - - - - -\n",
    "    \"\"\")\n",
    "test_answer = lgt.create_grid(\"\"\"\n",
    "    x - - - - -\n",
    "    - x - - - -\n",
    "    - - x - - -\n",
    "    - - - x - -\n",
    "    - - - - x -\n",
    "    - - - - - x\n",
    "    \"\"\")\n",
    "\n",
    "# Each time the exploration policy is called, randomness is used (a) to determine whether to\n",
    "# act randomly or follow the real policy and (b) if acting randomly, how to act. Here we\n",
    "# tell it to always act randomly, to make a full pass without activating any cells, to\n",
    "# activate four cells, and to make another full pass without activating any cells.\n",
    "test_agent = WorkingTraditionalAgent(random_source = fake_random_source([0.0, 0.0]*34 + [0.0, 1.0]*4 + [0.0, 0.0]*30))\n",
    "test_agent.train(test_grid, test_answer, verbose = True)\n",
    "lgt.display_grid(test_agent.get_grid())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we would expect moving on without activating to be encouraged at (1, 0) and discouraged at (3, 3), then activating the cell to be encouraged at (0, 0) and (once (0, 0) is activated) discouraged at (0, 1):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10  0]\n",
      "[-1  0]\n",
      "[  0 100]\n",
      "[   0 -100]\n"
     ]
    }
   ],
   "source": [
    "test_agent.set_grid(test_grid)\n",
    "\n",
    "for coords in [(1, 0), (3, 3), (0, 0), (0, 1)]:\n",
    "    test_agent._my_row, test_agent._my_col = coords\n",
    "    print(test_agent._q_table[test_agent._state_grid_to_n(test_agent.current_state_grid())])\n",
    "    if coords == (0, 0): test_agent.activate_current_cell()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great. Here's training the agent on a few thousand grids (takes about 12m on my machine):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training step 0 with an exploration rate of 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7_/d7tqnwgs3pb_q_t94nmtckdcx9mz_y/T/ipykernel_18541/2318334241.py:79: UserWarning: Encountered situation where all options lack training data, defaulting to 0\n",
      "  warnings.warn(\"Encountered situation where all options lack training data, defaulting to 0\")\n",
      "/var/folders/7_/d7tqnwgs3pb_q_t94nmtckdcx9mz_y/T/ipykernel_18541/2318334241.py:82: UserWarning: Encountered situation where some option lacks training data\n",
      "  warnings.warn(\"Encountered situation where some option lacks training data\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training step 1 with an exploration rate of 0.98\n",
      "Starting training step 2 with an exploration rate of 0.96\n",
      "Starting training step 3 with an exploration rate of 0.94\n",
      "Starting training step 4 with an exploration rate of 0.92\n",
      "Starting training step 5 with an exploration rate of 0.9\n",
      "Starting training step 6 with an exploration rate of 0.88\n",
      "Starting training step 7 with an exploration rate of 0.86\n",
      "Starting training step 8 with an exploration rate of 0.84\n",
      "Starting training step 9 with an exploration rate of 0.8200000000000001\n",
      "Starting training step 10 with an exploration rate of 0.8\n",
      "Starting training step 11 with an exploration rate of 0.78\n",
      "Starting training step 12 with an exploration rate of 0.76\n",
      "Starting training step 13 with an exploration rate of 0.74\n",
      "Starting training step 14 with an exploration rate of 0.72\n",
      "Starting training step 15 with an exploration rate of 0.7\n",
      "Starting training step 16 with an exploration rate of 0.6799999999999999\n",
      "Starting training step 17 with an exploration rate of 0.6599999999999999\n",
      "Starting training step 18 with an exploration rate of 0.64\n",
      "Starting training step 19 with an exploration rate of 0.62\n",
      "Starting training step 20 with an exploration rate of 0.6\n",
      "Starting training step 21 with an exploration rate of 0.5800000000000001\n",
      "Starting training step 22 with an exploration rate of 0.56\n",
      "Starting training step 23 with an exploration rate of 0.54\n",
      "Starting training step 24 with an exploration rate of 0.52\n",
      "Starting training step 25 with an exploration rate of 0.5\n",
      "Starting training step 26 with an exploration rate of 0.48\n",
      "Starting training step 27 with an exploration rate of 0.45999999999999996\n",
      "Starting training step 28 with an exploration rate of 0.43999999999999995\n",
      "Starting training step 29 with an exploration rate of 0.42000000000000004\n",
      "Starting training step 30 with an exploration rate of 0.4\n",
      "Starting training step 31 with an exploration rate of 0.38\n",
      "Starting training step 32 with an exploration rate of 0.36\n",
      "Starting training step 33 with an exploration rate of 0.33999999999999997\n",
      "Starting training step 34 with an exploration rate of 0.31999999999999995\n",
      "Starting training step 35 with an exploration rate of 0.30000000000000004\n",
      "Starting training step 36 with an exploration rate of 0.28\n",
      "Starting training step 37 with an exploration rate of 0.26\n",
      "Starting training step 38 with an exploration rate of 0.24\n",
      "Starting training step 39 with an exploration rate of 0.21999999999999997\n",
      "Starting training step 40 with an exploration rate of 0.19999999999999996\n",
      "Starting training step 41 with an exploration rate of 0.18000000000000005\n",
      "Starting training step 42 with an exploration rate of 0.16000000000000003\n",
      "Starting training step 43 with an exploration rate of 0.14\n",
      "Starting training step 44 with an exploration rate of 0.12\n",
      "Starting training step 45 with an exploration rate of 0.09999999999999998\n",
      "Starting training step 46 with an exploration rate of 0.07999999999999996\n",
      "Starting training step 47 with an exploration rate of 0.06000000000000005\n",
      "Starting training step 48 with an exploration rate of 0.040000000000000036\n",
      "Starting training step 49 with an exploration rate of 0.020000000000000018\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "random.seed(47)\n",
    "test_data = [lgt.generate_problem(10, 10, random.randrange(2), random.randrange(3), random.randrange(4)) for i in range(100)]\n",
    "\n",
    "agent = WorkingTraditionalAgent()\n",
    "random.seed(0)\n",
    "grids_per_step = 1_000\n",
    "n_steps = 50\n",
    "progress = []\n",
    "\n",
    "def test_agent(agent, test_data = test_data):\n",
    "    scores = Counter()\n",
    "    for problem, solution in test_data:\n",
    "        scores.update([agent.test(problem, solution)])\n",
    "    return scores\n",
    "\n",
    "for j in range(n_steps):\n",
    "    progress.append(test_agent(agent)[0])  # Keep track of the number of grids the agent gets perfectly\n",
    "    # Fully random exploration at the beginning of training, fully follow the real policy at the end\n",
    "    exploration_rate = 1 - j/n_steps\n",
    "    print(f\"Starting training step {j} with an exploration rate of {exploration_rate}\", flush = True)\n",
    "    for i in range(grids_per_step):\n",
    "        problem, solution = lgt.generate_problem(10, 10, random.randrange(2), random.randrange(3), random.randrange(4))\n",
    "        agent.train(problem, solution, exploration_rate = exploration_rate)\n",
    "progress.append(test_agent(agent)[0])\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And testing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final performance:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7_/d7tqnwgs3pb_q_t94nmtckdcx9mz_y/T/ipykernel_18541/2318334241.py:82: UserWarning: Encountered situation where some option lacks training data\n",
      "  warnings.warn(\"Encountered situation where some option lacks training data\")\n",
      "/var/folders/7_/d7tqnwgs3pb_q_t94nmtckdcx9mz_y/T/ipykernel_18541/2318334241.py:79: UserWarning: Encountered situation where all options lack training data, defaulting to 0\n",
      "  warnings.warn(\"Encountered situation where all options lack training data, defaulting to 0\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Counter({np.int64(0): 88,\n",
       "         np.int64(-1): 6,\n",
       "         np.int64(-2): 2,\n",
       "         np.int64(-15): 1,\n",
       "         np.int64(-14): 1,\n",
       "         np.int64(-5): 1,\n",
       "         np.int64(-3): 1})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.title(\"Learning curve\")\n",
    "plt.xlabel(\"Grids trained on\")\n",
    "plt.ylabel(\"Grids filled completely correctly (of 100)\")\n",
    "plt.ylim([0, 100])\n",
    "plt.plot(range(0, n_steps*grids_per_step+1, grids_per_step), progress)\n",
    "\n",
    "print(f\"Final performance:\")\n",
    "display(test_agent(agent))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On this amount of training, our agent is able to get a perfect score in roughly 90% of games. Training for longer improves this, and probably some tuning of hyperparameters could also help. But for now, let's move on to another way of solving this problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
